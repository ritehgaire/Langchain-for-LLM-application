{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6407c23d-5a05-477b-91f2-af0b2a4a4815",
   "metadata": {},
   "source": [
    "Cell 1: Install and Setup OpenAI API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4299140d-d8b0-4a5e-a24c-ee5a4dcaa6b5",
   "metadata": {},
   "source": [
    "This cell loads the OpenAI API key from a .env file using the dotenv library and sets up OpenAI authentication. It is required to make API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa81d591-fd9f-49aa-b419-13598be1c797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-dotenv\n",
    "#!pip install openai\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import openai\n",
    "\n",
    "# Find the .env file and load the environment variables\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Access the OpenAI API key from the environment\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Ensure the key is found\n",
    "if openai_api_key is None:\n",
    "    raise ValueError(\"API key not found. Check your .env file or environment variables.\")\n",
    "\n",
    "# Set the API key for OpenAI\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "# Now you can use the OpenAI API\n",
    "response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=\"Say this is a test\",\n",
    "    max_tokens=5\n",
    ")\n",
    "\n",
    "print(response.choices[0].text.strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ad92f9-b538-413a-bafa-0c605a6976b9",
   "metadata": {},
   "source": [
    "Cell 2: Model Deprecation Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9a71aa-3cd5-4ee8-a3f9-cda4610e9cb5",
   "metadata": {},
   "source": [
    "This cell dynamically selects the correct OpenAI model based on the current date. After June 12, 2024, it switches from gpt-3.5-turbo-0301 to gpt-3.5-turbo to handle API model deprecations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a05cbc-6b62-461d-b891-779418b2b34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: Account for model deprecation and switch models after June 12, 2024.\n",
    "\n",
    "import datetime\n",
    "\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should change to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Conditional check to switch model\n",
    "if current_date > target_date:\n",
    "    llm_model = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    llm_model = \"gpt-3.5-turbo-0301\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68192d44-3bef-4e9d-ae6e-41de27319b20",
   "metadata": {},
   "source": [
    "Cell 3: Function to Call OpenAI API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb37809-146f-437c-a7e5-18e00de3475c",
   "metadata": {},
   "source": [
    "This function sends a user-provided prompt to the OpenAI API using the specified model and returns the generated response. The temperature is set to 0 for consistent outputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f479a5-88f2-494b-ad6e-205387c63bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: A function to directly call OpenAI's ChatCompletion API for generating completions.\n",
    "\n",
    "def get_completion(prompt, model=llm_model):\n",
    "    # Set the user message for the model\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    # Send the prompt to the OpenAI API and get a response\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,  # Low temperature for deterministic results\n",
    "    )\n",
    "    # Return the model's response\n",
    "    return response.choices[0].message[\"content\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a59a42-6834-4507-8402-1c7f5d56a07d",
   "metadata": {},
   "source": [
    "Cell 4: Simple API Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec00e4bc-5bbe-443c-80e1-1c1e7a201fa3",
   "metadata": {},
   "source": [
    "This cell demonstrates how to call the get_completion function by passing a simple math question (What is 1+1?) to the OpenAI API and getting the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf0948f-c0c4-482e-8dfe-85313339cd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Calling the function to get a simple completion\n",
    "get_completion(\"What is 1+1?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12edb19b-03a2-472d-8363-ed3eda4c648f",
   "metadata": {},
   "source": [
    "Cell 5: Prompt to Translate Customer Email Using OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5c8b35-6542-49bd-83bc-946c78515627",
   "metadata": {},
   "source": [
    "This cell formats and sends a customer complaint written in pirate-style English to the OpenAI API, requesting a translation into calm and respectful American English.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74f26ad-3a2f-4091-b6e6-168ebc10ad71",
   "metadata": {},
   "source": [
    "# Purpose: Demonstrate how to format a prompt to translate text into a different style\n",
    "\n",
    "# Define the text and style\n",
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse,\\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\"\n",
    "style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\"\n",
    "\n",
    "# Create a formatted prompt by inserting the text and style\n",
    "prompt = f\"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \n",
    "into a style that is {style}.\n",
    "text: ```{customer_email}```\n",
    "\"\"\"\n",
    "\n",
    "# Print the prompt and get a completion\n",
    "print(prompt)\n",
    "response = get_completion(prompt)\n",
    "response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd579c1f-2615-4acc-942d-a7ee2f007e6a",
   "metadata": {},
   "source": [
    "Cell 6: Install LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1285193-7dd4-479c-b6c9-081a66a8166b",
   "metadata": {},
   "source": [
    "This cell installs the LangChain library, which is used for building applications that involve chaining large language models (LLMs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c44ba4-3f48-4bd2-80e3-0727e877c99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: Install LangChain library to interact with language models\n",
    "# !pip install --upgrade langchain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe5b17f-d159-4018-bb12-4c6ad69e74d9",
   "metadata": {},
   "source": [
    "Cell 7: Initialize LangChain Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba59a66f-56d9-471b-a352-7e6b212f1188",
   "metadata": {},
   "source": [
    "This cell sets up a LangChain model (ChatOpenAI) for interacting with OpenAI's GPT models. The temperature=0.0 ensures low randomness and deterministic output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231238bb-64e5-4c87-a177-56b922760cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: Demonstrate how to use LangChain for model interaction\n",
    "\n",
    "# Import the necessary class for ChatOpenAI from LangChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Initialize the model with the desired temperature (randomness control)\n",
    "chat = ChatOpenAI(temperature=0.0, model=llm_model)  # Same model and deterministic behavior (temp=0)\n",
    "chat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86323a19-10db-45bb-a962-243e31e8c543",
   "metadata": {},
   "source": [
    "Cell 8: Define LangChain Prompt Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d518e6-bf0b-416e-bca0-ff498726d5f8",
   "metadata": {},
   "source": [
    "This cell creates a prompt template using LangChain's ChatPromptTemplate. It is used to generate messages dynamically by filling in placeholders like {style} and {text}.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50201bdb-1089-4272-8e18-c8604f3f8c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: Create a structured prompt using LangChain's ChatPromptTemplate\n",
    "\n",
    "template_string = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {style}. \\\n",
    "text: ```{text}```\n",
    "\"\"\"\n",
    "\n",
    "# Import the prompt template class from LangChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Create the prompt template\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "\n",
    "# Check the prompt structure and variables\n",
    "print(prompt_template.messages[0].prompt.input_variables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365cf822-204f-4fd2-8d47-8453c9b14783",
   "metadata": {},
   "source": [
    "Cell 9: Format LangChain Messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c2d863-98ed-4785-ac37-afe2433e2372",
   "metadata": {},
   "source": [
    "This cell formats a customer message by applying the predefined LangChain prompt template, generating a message that will be sent to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69130b7-3f54-4ea3-862c-81f356878c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the customer style and email\n",
    "customer_style = \"\"\"American English in a calm and respectful tone\"\"\"\n",
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! \n",
    "And to make matters worse, the warranty don't cover the cost of cleaning up me kitchen. \n",
    "I need yer help right now, matey!\n",
    "\"\"\"\n",
    "\n",
    "# Format the prompt using the template\n",
    "customer_messages = prompt_template.format_messages(style=customer_style, text=customer_email)\n",
    "\n",
    "# Display the customer message object and the first message content\n",
    "print(type(customer_messages))\n",
    "print(type(customer_messages[0]))\n",
    "print(customer_messages[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a70813b-bb7d-487e-8f9e-c44ce2af547a",
   "metadata": {},
   "source": [
    "Cell 10: Call LangChain Model to Generate Response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a502795d-d01d-4fc9-8127-3e0885cbeff1",
   "metadata": {},
   "source": [
    "This cell sends the formatted customer message to the LangChain model and prints the model's response (translated into a calm and respectful tone)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa031b22-5c96-477a-88f5-29c4e2c9ba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the model to translate the message using the defined style\n",
    "customer_response = chat(customer_messages)\n",
    "\n",
    "# Output the model's response\n",
    "print(customer_response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0486aa8-7f77-42be-a0bf-b868febd9ca7",
   "metadata": {},
   "source": [
    "Cell 11: Translate Service Reply into Pirate English\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de20cdb8-6038-412b-97d3-a71179fa0001",
   "metadata": {},
   "source": [
    "This cell translates a service reply into Pirate English using LangChain's model by formatting the message and calling the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d08047-27f4-4e92-9e67-af9f35ab2ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: Translating another text (service reply) to Pirate English\n",
    "\n",
    "# Define a service reply and style to translate into Pirate English\n",
    "service_reply = \"\"\"Hey there customer, the warranty does not cover cleaning expenses for your kitchen because it's your fault that you misused your blender by forgetting to put the lid on before starting the blender. Tough luck! See ya!\"\"\"\n",
    "service_style_pirate = \"a polite tone that speaks in English Pirate\"\n",
    "\n",
    "# Format the service message\n",
    "service_messages = prompt_template.format_messages(style=service_style_pirate, text=service_reply)\n",
    "\n",
    "# Print the formatted service message\n",
    "print(service_messages[0].content)\n",
    "\n",
    "# Get the translation response from the model\n",
    "service_response = chat(service_messages)\n",
    "print(service_response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c2ff56-1709-4b00-9eea-57f4717ab2ab",
   "metadata": {},
   "source": [
    "Cell 12: Extract Structured Data from a Customer Review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626cf75f-45e7-47ce-a4b7-24e78fbcde0e",
   "metadata": {},
   "source": [
    "This cell extracts structured information (gift status, delivery days, and price comments) from an unstructured customer review using LangChain's template and model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26903ef0-737c-4af0-9710-2b99f5438c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: Extract specific structured data (gift, delivery days, price) from an unstructured review\n",
    "\n",
    "customer_review = \"\"\"\\\n",
    "This leaf blower is pretty amazing.  It has four settings: candle blower, gentle breeze, windy city, and tornado. \n",
    "It arrived in two days, just in time for my wife's anniversary present. \n",
    "I think my wife liked it so much she was speechless. \n",
    "So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. \n",
    "It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\n",
    "\"\"\"\n",
    "\n",
    "# Define the review template\n",
    "review_template = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price, and output them as a comma separated Python list.\n",
    "\n",
    "Format the output as JSON with the following keys: gift, delivery_days, price_value\n",
    "\n",
    "text: {text}\n",
    "\"\"\"\n",
    "\n",
    "# Create the prompt template from the review template\n",
    "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
    "\n",
    "# Format the message with customer review\n",
    "messages = prompt_template.format_messages(text=customer_review)\n",
    "\n",
    "# Call the model to get structured output\n",
    "chat = ChatOpenAI(temperature=0.0, model=llm_model)\n",
    "response = chat(messages)\n",
    "\n",
    "# Print the model's response\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384add21-9ba9-45b4-a24d-68e6455d4329",
   "metadata": {},
   "source": [
    "Cell 13: Parse Model Output into a Dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0c5753-d6c0-412a-bb1b-5ba63e8e4298",
   "metadata": {},
   "source": [
    "This cell defines schemas for the data we want to extract (gift status, delivery days, price value) and generates format instructions for parsing the model's output into a structured Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c7deb6-4cd0-4337-8f34-4380d50e59a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: Parse the LLM output into a structured Python dictionary\n",
    "\n",
    "# Import necessary parsers from LangChain\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "\n",
    "# Define response schemas for each piece of data we want to extract\n",
    "gift_schema = ResponseSchema(name=\"gift\", description=\"Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\")\n",
    "delivery_days_schema = ResponseSchema(name=\"delivery_days\", description=\"How many days did it take for the product to arrive? If this information is not found, output -1.\")\n",
    "price_value_schema = ResponseSchema(name=\"price_value\", description=\"Extract any sentences about the value or price, and output them as a comma separated Python list.\")\n",
    "\n",
    "# Combine all schemas into a list\n",
    "response_schemas = [gift_schema, delivery_days_schema, price_value_schema]\n",
    "\n",
    "# Create a StructuredOutputParser using the response schemas\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "# Get format instructions for the parser\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "# Print format instructions to see the expected structure\n",
    "print(format_instructions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0473bb84-c912-4618-ab99-e88ef35dbab7",
   "metadata": {},
   "source": [
    "Cell 14: Apply Output Parser to Extract Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da9a8fb-45c0-47ca-a69f-4cafd049fade",
   "metadata": {},
   "source": [
    "This cell combines the output parser's format instructions with the review extraction template. It sends the prompt to the LangChain model and parses the model’s output into a structured Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcecff35-dfec-4477-9eaf-471000b1466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: Integrate format instructions into the review extraction prompt\n",
    "\n",
    "# Update the review template with format instructions\n",
    "review_template_2 = f\"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price, and output them as a comma separated Python list.\n",
    "\n",
    "text: {{text}}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "# Create the prompt with the updated format instructions\n",
    "prompt = ChatPromptTemplate.from_template(template=review_template_2)\n",
    "\n",
    "# Format the message with review and format instructions\n",
    "messages = prompt.format_messages(text=customer_review, format_instructions=format_instructions)\n",
    "\n",
    "# Print the message to be sent to the model\n",
    "print(messages[0].content)\n",
    "\n",
    "# Get the model's response\n",
    "response = chat(messages)\n",
    "print(response.content)\n",
    "\n",
    "# Parse the response into a Python dictionary\n",
    "output_dict = output_parser.parse(response.content)\n",
    "\n",
    "# Check the output dictionary and the value for \"delivery_days\"\n",
    "output_dict\n",
    "output_dict.get('delivery_days')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa786442-1717-47ec-b7e3-27f7ad510236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4fa2a4-bdf1-4466-8f8f-986845a66381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1330c30-cf58-4c2b-b4b5-e37d08aa9052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab46411-e749-4cc0-9a49-3ec6e94ff255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc02ff95-5603-4c49-921f-e0b71509de3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4176b1a6-1371-47f2-80c8-f51e14f5ea86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080c9fed-fdf8-4064-adcf-1d9e9fc450b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372f2c52-8976-4ec6-8429-05ce7637ec68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e0c0dd-67ff-4ed2-b4db-865a4deaef00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26785632-b5ee-44e4-9f4b-02342820f18c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b63b5a1-49fb-4555-a7ad-443e5ce4f323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6f9d0c-110b-49ca-9f52-ddd057b40ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61990b5-c4d8-428e-b3c2-88ce0594936e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c1ee06-8f67-4335-81ad-9b01d1b89981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d287fe15-9876-489a-bd3b-bc856c167418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07949c5e-359a-4241-b86a-ea0735d7a690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10637c21-86fc-4554-8c95-b199314a79e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421e0f43-c2d4-4f8a-b130-e47aaab6e304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65594355-d51e-4ff1-8d6a-2ec43a752ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57853a9-9e8f-487a-bf29-1924be7bb845",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
